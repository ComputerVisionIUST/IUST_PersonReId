# مجموعه داده IUST_PersonReID  
<div align="center">
 
[![en](https://img.shields.io/badge/Language-English-red.svg)](https://github.com/ComputerVisionIUST/IUST_PersonReId/blob/main/README.md)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Q_lA1Hi_SqVnYueyqlhTaxM2SpbRsd_K?usp=sharing)

</div>

![Dataset Overview](https://github.com/IRIUST/Iranians_Reid_dataset/assets/141324225/782122d5-235a-4314-9d81-7eceec56c960)

## درباره مجموعه داده
مجموعه داده **IUST_PersonReID** برای رفع محدودیت‌های موجود در مجموعه‌داده‌های بازشناسی انسان با در نظر گرفتن زمینه‌های فرهنگی و محیطی منحصربه‌فرد کشورهای **اسلامی**، به‌ویژه ایران و عراق، توسعه یافته است. برخلاف مجموعه‌داده‌های معروف که سبک‌های پوشش رایج در این مناطق—مانند حجاب‌ و سایر پوشش‌ها—را منعکس نمی‌کنند، مجموعه داده IUST_PersonReID این تنوع را به تصویر می‌کشد و به کاهش **وابستگی جغرافیایی** و بهبود دقت مدل کمک می‌کند. این مجموعه‌داده از محیط‌های واقعی مختلف با شرایط نوری، زوایای دوربین، محیط‌های داخلی و خارجی و شرایط جوی مختلف جمع‌آوری شده است و نمای گسترده و مشترک از چندین دوربین را فراهم می‌کند. با ثبت این شرایط منحصربه‌فرد، IUST_PersonReID منبع ارزشمندی برای توسعه مدل‌های بازشناسی انسان ارائه می‌دهد که در محیط‌های متنوع به طور قابل‌اعتمادتر عمل می‌کنند.

### مکان‌های ضبط ویدئو
ویدیوها در مکان‌های زیر ضبط شده‌اند که جزئیات آن‌ها در جدول زیر خلاصه شده است:

| مکان                                          | دوربین‌ها | ساعات کل | وضوح          | تعداد روزها |
|-----------------------------------------------|-----------|----------|---------------|-------------|
| دانشگاه علم و فناوری ایران                  | 17        | 383      | متغیر        | 5           |
| مسجد الائمه                                   | 5         | 40       | 960×1080     | 2           |
| مغازه میوه‌فروشی محلی                        | 7         | 38       | 944×1080     | 1           |
| سوپرمارکت محلی                               | 6         | 124      | 1280×1944    | 4           |
| پیاده‌روی اربعین                             | 2         | 3        | 1280×720     | 5           |

### مقایسه مجموعه‌داده
جدول زیر مجموعه‌داده ما را با چندین مجموعه‌داده معروف مقایسه می‌کند:

| مجموعه‌داده    | مکان                | ID (چند دوربین) | ID (تک دوربین) | صحنه‌ها | تصاویر    |
|----------------|---------------------|--------------------|-------------------|---------|-----------|
| [SoccerNet-ReID](https://github.com/SoccerNet/sn-reid)   | لیگ‌های فوتبال        | 243,432             | -                 | -       | 340,993   |
| [MSMT17](https://www.pkuvmc.com/dataset.html)     | دانشگاه               | 4,101               | -                 | 15      | 126,441   |
| [Duke](https://paperswithcode.com/dataset/dukemtmc-reid)       | دانشگاه دوک          | 1,413               | 439               | 8       | 466,261   |
| [MARS](http://zheng-lab.cecs.anu.edu.au/Project/project_mars.html)       | دانشگاه تسینگ‌هوا    | 1,261               | -                 | 6       | 1,191,003  |
| [Market1501](https://paperswithcode.com/dataset/market-1501) | سوپرمارکت، تسینگ‌هوا| 1,501               | -                 | 6       | 32,217    |
| **IUST_PersonReID**   | **مکان‌های مختلف در ایران و عراق** | **1,847**           | **-**            | **19**   | **118,883** |

### آمار برچسب‌گذاری
این مجموعه‌داده شامل 118,883 تصویر است که 1,847 هویت منحصر به فرد را در حدود 20 صحنه مختلف به تصویر می‌کشد. هویت‌ها از زوایای دوربین‌های متعدد ثبت شده‌اند. شما می‌توانید توزیع هویت‌ها در دوربین‌ها را در تصویر زیر مشاهده کنید.

<p align="center">
  <img src="https://github.com/user-attachments/assets/b94e5b53-8a8f-433c-a562-87f6d6af7381" width="500" alt="تعداد ID ها در هر دوربین" />
</p>

## ویژگی‌های کلیدی مجموعه‌داده

1. **تشخیص و ردیابی خودکار انسان**: ما از مدل‌های مختلف ردیابی انسان برای برچسب‌گذاری اولیه داده‌های خود استفاده کردیم و الگوریتم‌هایی را انتخاب کردیم که در هر یک از محیط‌ها بهترین عملکرد را دارند. این رویکرد از نقاط قوت منحصربه‌فرد هر مدل برای هر محیط استفاده کرده‌است. مجموعه‌داده ما با استفاده از مدل‌های [YOLOv5](https://docs.ultralytics.com/models/yolov5/)، [YOLOv8](https://docs.ultralytics.com/models/yolov8/) با ByteTrack، [FairMOT](https://github.com/ifzhang/FairMOT) و [YOLOE](https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.7/deploy/pipeline/docs/tutorials/pphuman_mot_en.md) که روی مجموعه‌داده [CrowdHuman](https://www.crowdhuman.org/) آموزش دیده‌است، برچسب‌گذاری اولیه شد.

2. **نظارت انسانی برای دقت بیشتر**: افراد برچسب‌گذار از ابزار [CVAT](https://github.com/cvat-ai/cvat) برای اصلاح خروجی‌ مدل‌های ردیابی استفاده کردند و خطاهای مدل را مانند عدم تشخیص و موارد چالش‌برانگیز مانند انسداد، افراد محجبه و غیره را اصلاح کردند. این فرایند به‌طور قابل‌توجهی دقت و کیفیت مجموعه‌داده را بهبود بخشید.

3. **مدل بازشناسی انسان**: برای کمک به بازشناسی انسان در دوربین‌های مختلف، ما از یک مدل بازشناسی از پیش‌آموزش دیده بر اساس مدل [Swin Transformer](https://github.com/layumi/Person_reID_baseline_pytorch) استفاده کردیم که بر روی تصاویر برش‌خورده اعمال می‌شود تا داده‌های ما را برچسب‌گذاری اولیه کند.

4. **اصلاح بازشناسی با نظارت انسانی**: افراد برچسب‌گذار همچنین خطاهای فرایند بازشناسی را در دوربین‌ها با استفاده از ویژگی‌های زمانی و ظاهری اصلاح کردند. ما یک برنامه تحت وب برای تسهیل این فرایند برچسب‌گذاری توسعه دادیم که اکنون به‌صورت عمومی در [CVLab-ReId-Tool](https://github.com/ComputerVisionIUST/CVLab-ReId-Tool) در دسترس است، زیرا هیچ ابزار مشابهی پیش از این در دسترسی عموم قرار نداشت.

برای مشاهده دستورالعمل‌های برچسب‌گذاری، لطفاً به [مستندات حاشیه‌نویسی](https://docs.google.com/document/d/1rZ8E1QVWvn_c9F-WZDP7kzvAkSqddh-mRWyCYfB-iZY/edit?usp=sharing) ارائه شده به برچسب‌گذاران مراجعه کنید.

### نمایش محدودیت‌های مدل‌های هوش مصنوعی
با وجود پیشرفت‌های انجام شده در حوزه بینایی ماشین، مدل‌ها کماکان در پردازش داده‌های ویدیویی با مشکلاتی مواجه هستند و اغلب منجر به تشخیص‌های نادرست در ردیابی افراد می‌شوند. ویدیوی زیر این محدودیت‌ها را به تصویر می‌کشد.

https://github.com/user-attachments/assets/4cef8880-6f00-43e4-a52d-eb3f8657c31b

برای غلبه بر این مشکلات، ما از نظارت انسانی برای بهبود دقت تشخیص و ردیابی استفاده کردیم و از این طریق کیفیت مجموعه‌داده را افزایش دادیم.

### تنوع پوشش افراد در طول زمان
این مجموعه‌داده همچنین تصاویری از افراد را شامل می‌شود که

 در زمان‌های مختلف لباس‌های متفاوتی به تن دارند. به عنوان مثال، یک فرد در ابتدا با پوشش چادر و بعداً با یک مانتو در تصویر دیده شده‌است.

![clothing-variations-over-time](https://github.com/user-attachments/assets/ddba33b4-cd60-4d38-bea4-e2473b78206c)


## دریافت مجموعه‌داده

شما می‌توانید مجموعه‌داده را از [Google Drive](https://zaya.io/iust_personreid) دانلود کنید.

### نحوه نام‌گذاری تصاویر

مجموعه‌داده **IUST_PersonReID** از فرمت یکسان با مجموعه‌داده Market-1501 استفاده می‌کند. فرمت نام‌گذاری تصویر به صورت زیر است:

```
<personID>_<cameraID>_<sequenceID>_<frameID>.<extension>
```

#### اجزای تشکیل‌دهنده نام تصویر

1. **personID**: یک شناسه منحصر به فرد برای هر فرد در مجموعه‌داده که از `0001` تا تعداد کل افراد شناسایی شده متغیر است.

2. **cameraID**: یک شناسه تک رقمی که دوربینی را که تصویر را ضبط کرده است نشان می‌دهد. این شناسه از `1` تا تعداد کل دوربین‌های استفاده شده در مجموعه داده متغیر است.

3. **sequenceID**: در مجموعه‌داده **IUST_PersonReID**، این فیلد معمولاً به‌صورت ثابت به `s1` است، زیرا تغییر چندانی ندارد.

4. **frameID**: یک شماره منحصر به فرد که نشان می‌دهد فرد در کدام فریم ظاهر شده است. این امر برای تمایز تصاویر ضبط شده در سرعت‌های بالا از همان فرد و دوربین بسیار مهم است.

5. **extension**: فرمت فایل تصویر، معمولاً `.jpg` است.

#### نام تصویر نمونه

یک نام فایل نمونه در مجموعه‌داده **IUST_PersonReID** به صورت زیر است:

```
0001_c1_s1_000151.jpg
```

#### نشان‌دهنده:

- **0001**: `personID` = `0001`
- **c1**: `cameraID` = `1`
- **s1**: `sequenceID` = `1` (که در این مجموعه داده معمولاً ثابت است)
- **000151**: `frameID` = `151`

هر تصویر نمای برش خورده یک هویت را که توسط یکی از دوربین‌ها در یک محیط ثبت شده است را نمایش می‌دهد. `personID` و `cameraID` برای وظایف شناسایی مجدد افراد که هدف آن مطابقت تصاویر یک فرد در نماهای دوربین‌های مختلف است، اهمیت زیادی دارند.

## آموزش و ارزیابی مدل بازشناسی SOLIDER

ما یک **مدل باشناسی انسان به نام SOLIDER** را با استفاده از مجموعه‌داده **IUST_PersonReID** آموزش دادیم تا عملکرد آن را روی این مجموعه‌داده، مانند تغییر لباس و محیط‌های مختلف، به نمایش بگذاریم.

| Model | Rank-1 | Rank-5 | Rank-10 | mAP |
|------|--------|--------|---------|-----|
|SOLIDER| 51.08%      | 65.32%      | 70.76%       | 42.35%   |

برای راحتی بازتولید نتایج، یک [**Google Colab notebook**](https://colab.research.google.com/drive/1Q_lA1Hi_SqVnYueyqlhTaxM2SpbRsd_K?usp=sharing) ایجاد کردیم که به کاربران این امکان می‌دهد که مدل را بر روی این مجموعه‌داده آموزش و آزمایش کنند. این notebook دستورالعمل‌های آموزش و ارزیابی مدل را دارا است.
